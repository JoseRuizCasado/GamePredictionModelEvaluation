{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Game Prediction Models Evaluation\n",
    "## Needed imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     Local_TmOffRtg  Local_TmFloor%  Local_TmDefRtg  Local_Pace  Local_TS%  \\\n0        106.326895        0.480894      100.864813   93.274918   0.579954   \n1        106.326895        0.480894      100.864813   93.274918   0.579954   \n2        106.326895        0.480894      100.864813   93.274918   0.579954   \n3        106.326895        0.480894      100.864813   93.274918   0.579954   \n4        106.326895        0.480894      100.864813   93.274918   0.579954   \n..              ...             ...             ...         ...        ...   \n627      106.494585        0.480980      119.635230   87.074037   0.566133   \n628      106.494585        0.480980      119.635230   87.074037   0.566133   \n629      106.494585        0.480980      119.635230   87.074037   0.566133   \n630      106.494585        0.480980      119.635230   87.074037   0.566133   \n631      106.494585        0.480980      119.635230   87.074037   0.566133   \n\n     Local_eFG%  Local_FTARate  Local_3FGARate  Local_TmOR%  Local_TmDR%  ...  \\\n0      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n1      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n2      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n3      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n4      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n..          ...            ...             ...          ...          ...  ...   \n627    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n628    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n629    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n630    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n631    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n\n     Visitor_TS%  Visitor_eFG%  Visitor_FTARate  Visitor_3FGARate  \\\n0       0.538690      0.477319         0.296446          0.266108   \n1       0.566133      0.487970         0.290705          0.318392   \n2       0.535670      0.477748         0.217507          0.206307   \n3       0.571810      0.508089         0.253146          0.282205   \n4       0.567381      0.478923         0.323839          0.192538   \n..           ...           ...              ...               ...   \n627     0.593453      0.523714         0.321761          0.302852   \n628     0.601352      0.521150         0.309096          0.252419   \n629     0.579954      0.514913         0.241137          0.316263   \n630     0.564315      0.490814         0.288426          0.299755   \n631     0.557686      0.482662         0.261403          0.255802   \n\n     Visitor_TmOR%  Visitor_TmDR%  Visitor_BLK%  Visitor_TOV%  Visitor_STL%  \\\n0        28.615702      77.177177      5.442698     12.049168      7.804251   \n1        19.164345      77.393453      8.911307     10.418630      6.645854   \n2        23.866896      76.325088      6.382061     13.575965      7.993861   \n3        21.128451      76.812500      6.345733     13.156047      9.519718   \n4        24.899598      76.502732      8.295123     13.517942      8.438790   \n..             ...            ...           ...           ...           ...   \n627      22.086638      74.622532      9.150613     11.785222      8.670923   \n628      31.235828      75.572519     10.282776     13.567750      7.846969   \n629      20.654628      74.140753      9.227723     13.432928     10.002664   \n630      25.589837      75.406758      7.170966     13.369487      8.775888   \n631      25.108696      75.139807      9.274194     12.258092      6.531878   \n\n     Win  \n0      0  \n1      1  \n2      1  \n3      1  \n4      0  \n..   ...  \n627    0  \n628    0  \n629    1  \n630    1  \n631    1  \n\n[632 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Local_TmOffRtg</th>\n      <th>Local_TmFloor%</th>\n      <th>Local_TmDefRtg</th>\n      <th>Local_Pace</th>\n      <th>Local_TS%</th>\n      <th>Local_eFG%</th>\n      <th>Local_FTARate</th>\n      <th>Local_3FGARate</th>\n      <th>Local_TmOR%</th>\n      <th>Local_TmDR%</th>\n      <th>...</th>\n      <th>Visitor_TS%</th>\n      <th>Visitor_eFG%</th>\n      <th>Visitor_FTARate</th>\n      <th>Visitor_3FGARate</th>\n      <th>Visitor_TmOR%</th>\n      <th>Visitor_TmDR%</th>\n      <th>Visitor_BLK%</th>\n      <th>Visitor_TOV%</th>\n      <th>Visitor_STL%</th>\n      <th>Win</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.538690</td>\n      <td>0.477319</td>\n      <td>0.296446</td>\n      <td>0.266108</td>\n      <td>28.615702</td>\n      <td>77.177177</td>\n      <td>5.442698</td>\n      <td>12.049168</td>\n      <td>7.804251</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>8.911307</td>\n      <td>10.418630</td>\n      <td>6.645854</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.535670</td>\n      <td>0.477748</td>\n      <td>0.217507</td>\n      <td>0.206307</td>\n      <td>23.866896</td>\n      <td>76.325088</td>\n      <td>6.382061</td>\n      <td>13.575965</td>\n      <td>7.993861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.571810</td>\n      <td>0.508089</td>\n      <td>0.253146</td>\n      <td>0.282205</td>\n      <td>21.128451</td>\n      <td>76.812500</td>\n      <td>6.345733</td>\n      <td>13.156047</td>\n      <td>9.519718</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.567381</td>\n      <td>0.478923</td>\n      <td>0.323839</td>\n      <td>0.192538</td>\n      <td>24.899598</td>\n      <td>76.502732</td>\n      <td>8.295123</td>\n      <td>13.517942</td>\n      <td>8.438790</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.593453</td>\n      <td>0.523714</td>\n      <td>0.321761</td>\n      <td>0.302852</td>\n      <td>22.086638</td>\n      <td>74.622532</td>\n      <td>9.150613</td>\n      <td>11.785222</td>\n      <td>8.670923</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.601352</td>\n      <td>0.521150</td>\n      <td>0.309096</td>\n      <td>0.252419</td>\n      <td>31.235828</td>\n      <td>75.572519</td>\n      <td>10.282776</td>\n      <td>13.567750</td>\n      <td>7.846969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>9.227723</td>\n      <td>13.432928</td>\n      <td>10.002664</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.564315</td>\n      <td>0.490814</td>\n      <td>0.288426</td>\n      <td>0.299755</td>\n      <td>25.589837</td>\n      <td>75.406758</td>\n      <td>7.170966</td>\n      <td>13.369487</td>\n      <td>8.775888</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.557686</td>\n      <td>0.482662</td>\n      <td>0.261403</td>\n      <td>0.255802</td>\n      <td>25.108696</td>\n      <td>75.139807</td>\n      <td>9.274194</td>\n      <td>12.258092</td>\n      <td>6.531878</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>632 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv('PredictGamesDataset.csv')\n",
    "del data['Local_Team_id']\n",
    "del data['Visitor_Team_id']\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need to divide the data set into input and class for each dataset row."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     Local_TmOffRtg  Local_TmFloor%  Local_TmDefRtg  Local_Pace  Local_TS%  \\\n0        106.326895        0.480894      100.864813   93.274918   0.579954   \n1        106.326895        0.480894      100.864813   93.274918   0.579954   \n2        106.326895        0.480894      100.864813   93.274918   0.579954   \n3        106.326895        0.480894      100.864813   93.274918   0.579954   \n4        106.326895        0.480894      100.864813   93.274918   0.579954   \n..              ...             ...             ...         ...        ...   \n627      106.494585        0.480980      119.635230   87.074037   0.566133   \n628      106.494585        0.480980      119.635230   87.074037   0.566133   \n629      106.494585        0.480980      119.635230   87.074037   0.566133   \n630      106.494585        0.480980      119.635230   87.074037   0.566133   \n631      106.494585        0.480980      119.635230   87.074037   0.566133   \n\n     Local_eFG%  Local_FTARate  Local_3FGARate  Local_TmOR%  Local_TmDR%  ...  \\\n0      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n1      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n2      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n3      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n4      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n..          ...            ...             ...          ...          ...  ...   \n627    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n628    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n629    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n630    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n631    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n\n     Visitor_Pace  Visitor_TS%  Visitor_eFG%  Visitor_FTARate  \\\n0       91.701077     0.538690      0.477319         0.296446   \n1       87.074037     0.566133      0.487970         0.290705   \n2       91.688075     0.535670      0.477748         0.217507   \n3       94.194271     0.571810      0.508089         0.253146   \n4       90.892768     0.567381      0.478923         0.323839   \n..            ...          ...           ...              ...   \n627     93.469083     0.593453      0.523714         0.321761   \n628     92.665032     0.601352      0.521150         0.309096   \n629     93.274918     0.579954      0.514913         0.241137   \n630     87.274997     0.564315      0.490814         0.288426   \n631     90.798947     0.557686      0.482662         0.261403   \n\n     Visitor_3FGARate  Visitor_TmOR%  Visitor_TmDR%  Visitor_BLK%  \\\n0            0.266108      28.615702      77.177177      5.442698   \n1            0.318392      19.164345      77.393453      8.911307   \n2            0.206307      23.866896      76.325088      6.382061   \n3            0.282205      21.128451      76.812500      6.345733   \n4            0.192538      24.899598      76.502732      8.295123   \n..                ...            ...            ...           ...   \n627          0.302852      22.086638      74.622532      9.150613   \n628          0.252419      31.235828      75.572519     10.282776   \n629          0.316263      20.654628      74.140753      9.227723   \n630          0.299755      25.589837      75.406758      7.170966   \n631          0.255802      25.108696      75.139807      9.274194   \n\n     Visitor_TOV%  Visitor_STL%  \n0       12.049168      7.804251  \n1       10.418630      6.645854  \n2       13.575965      7.993861  \n3       13.156047      9.519718  \n4       13.517942      8.438790  \n..            ...           ...  \n627     11.785222      8.670923  \n628     13.567750      7.846969  \n629     13.432928     10.002664  \n630     13.369487      8.775888  \n631     12.258092      6.531878  \n\n[632 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Local_TmOffRtg</th>\n      <th>Local_TmFloor%</th>\n      <th>Local_TmDefRtg</th>\n      <th>Local_Pace</th>\n      <th>Local_TS%</th>\n      <th>Local_eFG%</th>\n      <th>Local_FTARate</th>\n      <th>Local_3FGARate</th>\n      <th>Local_TmOR%</th>\n      <th>Local_TmDR%</th>\n      <th>...</th>\n      <th>Visitor_Pace</th>\n      <th>Visitor_TS%</th>\n      <th>Visitor_eFG%</th>\n      <th>Visitor_FTARate</th>\n      <th>Visitor_3FGARate</th>\n      <th>Visitor_TmOR%</th>\n      <th>Visitor_TmDR%</th>\n      <th>Visitor_BLK%</th>\n      <th>Visitor_TOV%</th>\n      <th>Visitor_STL%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>91.701077</td>\n      <td>0.538690</td>\n      <td>0.477319</td>\n      <td>0.296446</td>\n      <td>0.266108</td>\n      <td>28.615702</td>\n      <td>77.177177</td>\n      <td>5.442698</td>\n      <td>12.049168</td>\n      <td>7.804251</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>8.911307</td>\n      <td>10.418630</td>\n      <td>6.645854</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>91.688075</td>\n      <td>0.535670</td>\n      <td>0.477748</td>\n      <td>0.217507</td>\n      <td>0.206307</td>\n      <td>23.866896</td>\n      <td>76.325088</td>\n      <td>6.382061</td>\n      <td>13.575965</td>\n      <td>7.993861</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>94.194271</td>\n      <td>0.571810</td>\n      <td>0.508089</td>\n      <td>0.253146</td>\n      <td>0.282205</td>\n      <td>21.128451</td>\n      <td>76.812500</td>\n      <td>6.345733</td>\n      <td>13.156047</td>\n      <td>9.519718</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>90.892768</td>\n      <td>0.567381</td>\n      <td>0.478923</td>\n      <td>0.323839</td>\n      <td>0.192538</td>\n      <td>24.899598</td>\n      <td>76.502732</td>\n      <td>8.295123</td>\n      <td>13.517942</td>\n      <td>8.438790</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>93.469083</td>\n      <td>0.593453</td>\n      <td>0.523714</td>\n      <td>0.321761</td>\n      <td>0.302852</td>\n      <td>22.086638</td>\n      <td>74.622532</td>\n      <td>9.150613</td>\n      <td>11.785222</td>\n      <td>8.670923</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>92.665032</td>\n      <td>0.601352</td>\n      <td>0.521150</td>\n      <td>0.309096</td>\n      <td>0.252419</td>\n      <td>31.235828</td>\n      <td>75.572519</td>\n      <td>10.282776</td>\n      <td>13.567750</td>\n      <td>7.846969</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>9.227723</td>\n      <td>13.432928</td>\n      <td>10.002664</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>87.274997</td>\n      <td>0.564315</td>\n      <td>0.490814</td>\n      <td>0.288426</td>\n      <td>0.299755</td>\n      <td>25.589837</td>\n      <td>75.406758</td>\n      <td>7.170966</td>\n      <td>13.369487</td>\n      <td>8.775888</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>90.798947</td>\n      <td>0.557686</td>\n      <td>0.482662</td>\n      <td>0.261403</td>\n      <td>0.255802</td>\n      <td>25.108696</td>\n      <td>75.139807</td>\n      <td>9.274194</td>\n      <td>12.258092</td>\n      <td>6.531878</td>\n    </tr>\n  </tbody>\n</table>\n<p>632 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "X_unscaled = data.iloc[:, :26]\n",
    "X_unscaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0      0\n1      1\n2      1\n3      1\n4      0\n      ..\n627    0\n628    0\n629    1\n630    1\n631    1\nName: Win, Length: 632, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "Y = data.iloc[:, 26]\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As seen in the input data it is necessary to pre-process the data. Differences in the scales across input variables may\n",
    "increase the difficulty of the problem being modeled. An example of this is that large input values can result in a\n",
    "model that learns large weight values. A model with large weight values is often unstable, meaning that it may suffer\n",
    "from poor performance during learning and sensitivity to input values resulting in higher generalization error."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.02104002, -0.3888855 , -0.81763465, ..., -1.80736562,\n        -0.85192723, -0.33766863],\n       [ 0.02104002, -0.3888855 , -0.81763465, ...,  0.49753131,\n        -2.40555684, -1.34760684],\n       [ 0.02104002, -0.3888855 , -0.81763465, ..., -1.18315728,\n         0.6028549 , -0.17235959],\n       ...,\n       [ 0.06623411, -0.38345585,  2.03779632, ...,  0.70778998,\n         0.46656447,  1.57899721],\n       [ 0.06623411, -0.38345585,  2.03779632, ..., -0.65892841,\n         0.40611638,  0.50944393],\n       [ 0.06623411, -0.38345585,  2.03779632, ...,  0.7386699 ,\n        -0.65285782, -1.44697559]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_unscaled)\n",
    "X = scaler.transform(X_unscaled)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whe we the have data scaled, it is time to divide the original data set into training set and test set. The test set\n",
    "size will be th 20% of the original dataset. Stratifying the data by the results, we manage to maintain the percentages\n",
    "of each class in both resulting sets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Classifier Models\n",
    "We are going to evaluate different models:\n",
    "* Logistic Regression. All different solver will be evaluates (lbfgs, newton-cg, liblinear, sag, saga).\n",
    "* Support Vector Machines. For classification Linear Support Vector Classifier will be used.\n",
    "* Random Forest.\n",
    "* Neuronal Network. For this classification Multi Layer Perceptron Classifier will be evaluated with different solvers\n",
    "(lbfgs, sgd, adam)\n",
    "\n",
    "The models will trained  in loop for 30 times to obtain the mean accuracy, then we will calculate the deviation to\n",
    "display in a plot. In each iteration of the loop the dataset will be splited in training and test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/joseluisruizcasado/anaconda3/envs/tfg-django-scikit/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/joseluisruizcasado/anaconda3/envs/tfg-django-scikit/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/joseluisruizcasado/anaconda3/envs/tfg-django-scikit/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/joseluisruizcasado/anaconda3/envs/tfg-django-scikit/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/joseluisruizcasado/anaconda3/envs/tfg-django-scikit/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Logistic Regression solver=lbfgs -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Logistic Regression solver=newton-cg -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Logistic Regression solver=liblinear -> train scores: [0.699009900990099, 0.700990099009901, 0.6996047430830039, 0.7015810276679841, 0.691699604743083] test scores: [0.6220472440944882, 0.6850393700787402, 0.6349206349206349, 0.7063492063492064, 0.5396825396825397]\n",
      "Logistic Regression solver=sag -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Logistic Regression solver=saga -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Support Vector Machines -> train scores: [0.7029702970297029, 0.7069306930693069, 0.7055335968379447, 0.7134387351778656, 0.7094861660079052] test scores: [0.5905511811023622, 0.6377952755905512, 0.5952380952380952, 0.7063492063492064, 0.5238095238095238]\n",
      "Random Forest -> train scores: [0.9425742574257425, 0.9386138613861386, 0.9407114624505929, 0.9387351778656127, 0.9426877470355731] test scores: [0.6456692913385826, 0.6692913385826772, 0.5555555555555556, 0.6825396825396826, 0.5793650793650794]\n",
      "Neuronal Network solver=lbfgs -> train scores: [0.9425742574257425, 0.9386138613861386, 0.9407114624505929, 0.9387351778656127, 0.9426877470355731] test scores: [0.5826771653543307, 0.6062992125984252, 0.49206349206349204, 0.5873015873015873, 0.49206349206349204]\n",
      "Neuronal Network solver=sgd -> train scores: [0.7663366336633664, 0.7742574257425743, 0.7707509881422925, 0.7628458498023716, 0.7490118577075099] test scores: [0.6062992125984252, 0.6299212598425197, 0.5793650793650794, 0.7222222222222222, 0.6507936507936508]\n",
      "Neuronal Network solver=adam -> train scores: [0.9425742574257425, 0.9386138613861386, 0.9407114624505929, 0.9387351778656127, 0.9426877470355731] test scores: [0.5826771653543307, 0.5984251968503937, 0.5, 0.6904761904761905, 0.5476190476190477]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_accuracy_LR_lbfgs = []\n",
    "test_accuracy_LR_lbfgs = []\n",
    "train_accuracy_LR_newton_cg = []\n",
    "test_accuracy_LR_newton_cg = []\n",
    "train_accuracy_LR_liblinear = []\n",
    "test_accuracy_LR_liblinear = []\n",
    "train_accuracy_LR_sag = []\n",
    "test_accuracy_LR_sag = []\n",
    "train_accuracy_LR_saga= []\n",
    "test_accuracy_LR_saga= []\n",
    "train_accuracy_SVM = []\n",
    "test_accuracy_SVM = []\n",
    "train_accuracy_RF = []\n",
    "test_accuracy_RF = []\n",
    "train_accuracy_NN_lbfgs = []\n",
    "test_accuracy_NN_lbfgs = []\n",
    "train_accuracy_NN_sgd = []\n",
    "test_accuracy_NN_sgd = []\n",
    "train_accuracy_NN_adam = []\n",
    "test_accuracy_NN_adam = []\n",
    "k_fold = KFold()\n",
    "for k, (train, test) in enumerate(k_fold.split(X, Y)):\n",
    "\n",
    "    LR_lbfgs = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_lbfgs.append(LR_lbfgs.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_lbfgs.append(LR_lbfgs.score(X[test], Y[test]))\n",
    "    LR_newton_cg = LogisticRegression(random_state=0, solver='newton-cg', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_newton_cg.append(LR_newton_cg.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_newton_cg.append(LR_newton_cg.score(X[test], Y[test]))\n",
    "    LR_liblinear = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_liblinear.append(LR_liblinear.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_liblinear.append(LR_liblinear.score(X[test], Y[test]))\n",
    "    LR_sag = LogisticRegression(random_state=0, solver='sag', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_sag.append(LR_sag.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_sag.append(LR_sag.score(X[test], Y[test]))\n",
    "    LR_saga = LogisticRegression(random_state=0, solver='saga', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_saga.append(LR_saga.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_saga.append(LR_saga.score(X[test], Y[test]))\n",
    "\n",
    "    SVM = svm.SVC(kernel='linear', probability=True).fit(X[train], Y[train])\n",
    "    train_accuracy_SVM.append(SVM.score(X[train], Y[train]))\n",
    "    test_accuracy_SVM.append(SVM.score(X[test], Y[test]))\n",
    "\n",
    "    RF = RandomForestClassifier().fit(X[train], Y[train])\n",
    "    train_accuracy_RF.append(RF.score(X[train], Y[train]))\n",
    "    test_accuracy_RF.append(RF.score(X[test], Y[test]))\n",
    "\n",
    "    NN_lbfgs = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1, max_iter=5000).fit(X[train], Y[train])\n",
    "    train_accuracy_NN_lbfgs.append(NN_lbfgs.score(X[train], Y[train]))\n",
    "    test_accuracy_NN_lbfgs.append(NN_lbfgs.score(X[test], Y[test]))\n",
    "    NN_sgd = MLPClassifier(solver='sgd', alpha=1e-5, random_state=1, max_iter=5000).fit(X[train], Y[train])\n",
    "    train_accuracy_NN_sgd.append(NN_sgd.score(X[train], Y[train]))\n",
    "    test_accuracy_NN_sgd.append(NN_sgd.score(X[test], Y[test]))\n",
    "    NN_adam = MLPClassifier(solver='adam', alpha=1e-5, random_state=1, max_iter=5000).fit(X[train], Y[train])\n",
    "    train_accuracy_NN_adam.append(NN_adam.score(X[train], Y[train]))\n",
    "    test_accuracy_NN_adam.append(NN_adam.score(X[test], Y[test]))\n",
    "\n",
    "print(f'Logistic Regression solver=lbfgs -> train scores: {train_accuracy_LR_lbfgs} test scores: {test_accuracy_LR_lbfgs}')\n",
    "print(f'Logistic Regression solver=newton-cg -> train scores: {train_accuracy_LR_newton_cg} '\n",
    "      f'test scores: {test_accuracy_LR_newton_cg}')\n",
    "print(f'Logistic Regression solver=liblinear -> train scores: {train_accuracy_LR_liblinear} '\n",
    "      f'test scores: {test_accuracy_LR_liblinear}')\n",
    "print(f'Logistic Regression solver=sag -> train scores: {train_accuracy_LR_sag} test scores: {test_accuracy_LR_sag}')\n",
    "print(f'Logistic Regression solver=saga -> train scores: {train_accuracy_LR_saga} test scores: {test_accuracy_LR_saga}')\n",
    "print(f'Support Vector Machines -> train scores: {train_accuracy_SVM} test scores: {test_accuracy_SVM}')\n",
    "print(f'Random Forest -> train scores: {train_accuracy_RF} test scores: {test_accuracy_RF}')\n",
    "print(f'Neuronal Network solver=lbfgs -> train scores: {train_accuracy_NN_lbfgs} test scores: {test_accuracy_NN_lbfgs}')\n",
    "print(f'Neuronal Network solver=sgd -> train scores: {train_accuracy_NN_sgd} test scores: {test_accuracy_NN_sgd}')\n",
    "print(f'Neuronal Network solver=adam -> train scores: {train_accuracy_NN_adam} test scores: {test_accuracy_NN_adam}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the data\n",
    "With stored accuracy for training and test set of each model the mean precision and standard deviation are plotted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ind: [0 1 2 3 4 5 6 7 8 9] Mean: (10,), sv (10,)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 1120x960 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['LR-lbfgs', 'L-newton-cg', 'LR-liblinear','LR-sag', 'LR-saga', 'SVM', 'RF', 'NN-lbfgs', 'NN-sgd', 'NN-adam']\n",
    "ind = np.arange(10)\n",
    "train_means_list = [sum(train_accuracy_LR_lbfgs)/len(train_accuracy_LR_lbfgs),\n",
    "               sum(train_accuracy_LR_newton_cg)/len(train_accuracy_LR_newton_cg),\n",
    "               sum(train_accuracy_LR_liblinear)/len(train_accuracy_LR_liblinear),\n",
    "               sum(train_accuracy_LR_sag)/len(train_accuracy_LR_sag),\n",
    "               sum(train_accuracy_LR_saga)/len(train_accuracy_LR_saga),\n",
    "               sum(train_accuracy_SVM)/len(train_accuracy_SVM),\n",
    "               sum(train_accuracy_RF)/len(train_accuracy_RF),\n",
    "               sum(train_accuracy_NN_lbfgs)/len(train_accuracy_NN_lbfgs),\n",
    "               sum(train_accuracy_NN_sgd)/len(train_accuracy_NN_sgd),\n",
    "               sum(train_accuracy_NN_adam)/len(train_accuracy_NN_adam)\n",
    "]\n",
    "train_standar_deviation_list = [\n",
    "    statistics.stdev(train_accuracy_LR_lbfgs),\n",
    "    statistics.stdev(train_accuracy_LR_newton_cg),\n",
    "    statistics.stdev(train_accuracy_LR_liblinear),\n",
    "    statistics.stdev(train_accuracy_LR_sag),\n",
    "    statistics.stdev(train_accuracy_LR_saga),\n",
    "    statistics.stdev(train_accuracy_SVM),\n",
    "    statistics.stdev(train_accuracy_RF),\n",
    "    statistics.stdev(train_accuracy_NN_lbfgs),\n",
    "    statistics.stdev(train_accuracy_NN_sgd),\n",
    "    statistics.stdev(train_accuracy_NN_adam),\n",
    "]\n",
    "test_means_list = [sum(test_accuracy_LR_lbfgs)/len(test_accuracy_LR_lbfgs),\n",
    "               sum(test_accuracy_LR_newton_cg)/len(test_accuracy_LR_newton_cg),\n",
    "               sum(test_accuracy_LR_liblinear)/len(test_accuracy_LR_liblinear),\n",
    "               sum(test_accuracy_LR_sag)/len(test_accuracy_LR_sag),\n",
    "               sum(test_accuracy_LR_saga)/len(test_accuracy_LR_saga),\n",
    "               sum(test_accuracy_SVM)/len(test_accuracy_SVM),\n",
    "               sum(test_accuracy_RF)/len(test_accuracy_RF),\n",
    "               sum(test_accuracy_NN_lbfgs)/len(test_accuracy_NN_lbfgs),\n",
    "               sum(test_accuracy_NN_sgd)/len(test_accuracy_NN_sgd),\n",
    "               sum(test_accuracy_NN_adam)/len(test_accuracy_NN_adam)\n",
    "]\n",
    "test_standar_deviation_list = [\n",
    "    statistics.stdev(test_accuracy_LR_lbfgs),\n",
    "    statistics.stdev(test_accuracy_LR_newton_cg),\n",
    "    statistics.stdev(test_accuracy_LR_liblinear),\n",
    "    statistics.stdev(test_accuracy_LR_sag),\n",
    "    statistics.stdev(test_accuracy_LR_saga),\n",
    "    statistics.stdev(test_accuracy_SVM),\n",
    "    statistics.stdev(test_accuracy_RF),\n",
    "    statistics.stdev(test_accuracy_NN_lbfgs),\n",
    "    statistics.stdev(test_accuracy_NN_sgd),\n",
    "    statistics.stdev(test_accuracy_NN_adam),\n",
    "]\n",
    "train_means = np.array(train_means_list)\n",
    "train_standar_deviation = np.array(train_standar_deviation_list)\n",
    "test_means = np.array(test_means_list)\n",
    "test_standar_deviation = np.array(test_standar_deviation_list)\n",
    "print(f'ind: {ind} Mean: {test_means.shape}, sv {test_standar_deviation.shape}')\n",
    "width = 0.35\n",
    "plt.figure(figsize=(14, 12), dpi=80)\n",
    "plt.bar(ind, test_means, width=width, yerr=test_standar_deviation, label='Test Score')\n",
    "plt.bar(ind + width, train_means, width=width,yerr=train_standar_deviation, label='Train Score')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Scores of each model')\n",
    "plt.xticks(ind + width / 2, models)\n",
    "plt.legend()\n",
    "plt.savefig('models-study-figures/models-score.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrices\n",
    "For each model we generate a confusion matrix."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_confusion_matrix(LR_lbfgs, x_test, y_test, display_labels=['Lose', 'Win'], cmap=plt.cm.Blues, normalize=None)\n",
    "\n",
    "plt.title('LR lbfgs solver confusion matrix')\n",
    "\n",
    "plt.savefig('models-study-figures/lr-lbfgs.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}