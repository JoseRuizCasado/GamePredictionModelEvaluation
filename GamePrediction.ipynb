{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Game Prediction Models Evaluation\n",
    "## Needed imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     Local_TmOffRtg  Local_TmFloor%  Local_TmDefRtg  Local_Pace  Local_TS%  \\\n0        106.326895        0.480894      100.864813   93.274918   0.579954   \n1        106.326895        0.480894      100.864813   93.274918   0.579954   \n2        106.326895        0.480894      100.864813   93.274918   0.579954   \n3        106.326895        0.480894      100.864813   93.274918   0.579954   \n4        106.326895        0.480894      100.864813   93.274918   0.579954   \n..              ...             ...             ...         ...        ...   \n627      106.494585        0.480980      119.635230   87.074037   0.566133   \n628      106.494585        0.480980      119.635230   87.074037   0.566133   \n629      106.494585        0.480980      119.635230   87.074037   0.566133   \n630      106.494585        0.480980      119.635230   87.074037   0.566133   \n631      106.494585        0.480980      119.635230   87.074037   0.566133   \n\n     Local_eFG%  Local_FTARate  Local_3FGARate  Local_TmOR%  Local_TmDR%  ...  \\\n0      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n1      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n2      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n3      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n4      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n..          ...            ...             ...          ...          ...  ...   \n627    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n628    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n629    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n630    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n631    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n\n     Visitor_TS%  Visitor_eFG%  Visitor_FTARate  Visitor_3FGARate  \\\n0       0.538690      0.477319         0.296446          0.266108   \n1       0.566133      0.487970         0.290705          0.318392   \n2       0.535670      0.477748         0.217507          0.206307   \n3       0.571810      0.508089         0.253146          0.282205   \n4       0.567381      0.478923         0.323839          0.192538   \n..           ...           ...              ...               ...   \n627     0.593453      0.523714         0.321761          0.302852   \n628     0.601352      0.521150         0.309096          0.252419   \n629     0.579954      0.514913         0.241137          0.316263   \n630     0.564315      0.490814         0.288426          0.299755   \n631     0.557686      0.482662         0.261403          0.255802   \n\n     Visitor_TmOR%  Visitor_TmDR%  Visitor_BLK%  Visitor_TOV%  Visitor_STL%  \\\n0        28.615702      77.177177      5.442698     12.049168      7.804251   \n1        19.164345      77.393453      8.911307     10.418630      6.645854   \n2        23.866896      76.325088      6.382061     13.575965      7.993861   \n3        21.128451      76.812500      6.345733     13.156047      9.519718   \n4        24.899598      76.502732      8.295123     13.517942      8.438790   \n..             ...            ...           ...           ...           ...   \n627      22.086638      74.622532      9.150613     11.785222      8.670923   \n628      31.235828      75.572519     10.282776     13.567750      7.846969   \n629      20.654628      74.140753      9.227723     13.432928     10.002664   \n630      25.589837      75.406758      7.170966     13.369487      8.775888   \n631      25.108696      75.139807      9.274194     12.258092      6.531878   \n\n     Win  \n0      0  \n1      1  \n2      1  \n3      1  \n4      0  \n..   ...  \n627    0  \n628    0  \n629    1  \n630    1  \n631    1  \n\n[632 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Local_TmOffRtg</th>\n      <th>Local_TmFloor%</th>\n      <th>Local_TmDefRtg</th>\n      <th>Local_Pace</th>\n      <th>Local_TS%</th>\n      <th>Local_eFG%</th>\n      <th>Local_FTARate</th>\n      <th>Local_3FGARate</th>\n      <th>Local_TmOR%</th>\n      <th>Local_TmDR%</th>\n      <th>...</th>\n      <th>Visitor_TS%</th>\n      <th>Visitor_eFG%</th>\n      <th>Visitor_FTARate</th>\n      <th>Visitor_3FGARate</th>\n      <th>Visitor_TmOR%</th>\n      <th>Visitor_TmDR%</th>\n      <th>Visitor_BLK%</th>\n      <th>Visitor_TOV%</th>\n      <th>Visitor_STL%</th>\n      <th>Win</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.538690</td>\n      <td>0.477319</td>\n      <td>0.296446</td>\n      <td>0.266108</td>\n      <td>28.615702</td>\n      <td>77.177177</td>\n      <td>5.442698</td>\n      <td>12.049168</td>\n      <td>7.804251</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>8.911307</td>\n      <td>10.418630</td>\n      <td>6.645854</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.535670</td>\n      <td>0.477748</td>\n      <td>0.217507</td>\n      <td>0.206307</td>\n      <td>23.866896</td>\n      <td>76.325088</td>\n      <td>6.382061</td>\n      <td>13.575965</td>\n      <td>7.993861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.571810</td>\n      <td>0.508089</td>\n      <td>0.253146</td>\n      <td>0.282205</td>\n      <td>21.128451</td>\n      <td>76.812500</td>\n      <td>6.345733</td>\n      <td>13.156047</td>\n      <td>9.519718</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>0.567381</td>\n      <td>0.478923</td>\n      <td>0.323839</td>\n      <td>0.192538</td>\n      <td>24.899598</td>\n      <td>76.502732</td>\n      <td>8.295123</td>\n      <td>13.517942</td>\n      <td>8.438790</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.593453</td>\n      <td>0.523714</td>\n      <td>0.321761</td>\n      <td>0.302852</td>\n      <td>22.086638</td>\n      <td>74.622532</td>\n      <td>9.150613</td>\n      <td>11.785222</td>\n      <td>8.670923</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.601352</td>\n      <td>0.521150</td>\n      <td>0.309096</td>\n      <td>0.252419</td>\n      <td>31.235828</td>\n      <td>75.572519</td>\n      <td>10.282776</td>\n      <td>13.567750</td>\n      <td>7.846969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>9.227723</td>\n      <td>13.432928</td>\n      <td>10.002664</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.564315</td>\n      <td>0.490814</td>\n      <td>0.288426</td>\n      <td>0.299755</td>\n      <td>25.589837</td>\n      <td>75.406758</td>\n      <td>7.170966</td>\n      <td>13.369487</td>\n      <td>8.775888</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>0.557686</td>\n      <td>0.482662</td>\n      <td>0.261403</td>\n      <td>0.255802</td>\n      <td>25.108696</td>\n      <td>75.139807</td>\n      <td>9.274194</td>\n      <td>12.258092</td>\n      <td>6.531878</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>632 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('PredictGamesDataset.csv')\n",
    "del data['Local_Team_id']\n",
    "del data['Visitor_Team_id']\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need to divide the data set into input and class for each dataset row."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     Local_TmOffRtg  Local_TmFloor%  Local_TmDefRtg  Local_Pace  Local_TS%  \\\n0        106.326895        0.480894      100.864813   93.274918   0.579954   \n1        106.326895        0.480894      100.864813   93.274918   0.579954   \n2        106.326895        0.480894      100.864813   93.274918   0.579954   \n3        106.326895        0.480894      100.864813   93.274918   0.579954   \n4        106.326895        0.480894      100.864813   93.274918   0.579954   \n..              ...             ...             ...         ...        ...   \n627      106.494585        0.480980      119.635230   87.074037   0.566133   \n628      106.494585        0.480980      119.635230   87.074037   0.566133   \n629      106.494585        0.480980      119.635230   87.074037   0.566133   \n630      106.494585        0.480980      119.635230   87.074037   0.566133   \n631      106.494585        0.480980      119.635230   87.074037   0.566133   \n\n     Local_eFG%  Local_FTARate  Local_3FGARate  Local_TmOR%  Local_TmDR%  ...  \\\n0      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n1      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n2      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n3      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n4      0.514913       0.241137        0.316263    20.654628    74.140753  ...   \n..          ...            ...             ...          ...          ...  ...   \n627    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n628    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n629    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n630    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n631    0.487970       0.290705        0.318392    19.164345    77.393453  ...   \n\n     Visitor_Pace  Visitor_TS%  Visitor_eFG%  Visitor_FTARate  \\\n0       91.701077     0.538690      0.477319         0.296446   \n1       87.074037     0.566133      0.487970         0.290705   \n2       91.688075     0.535670      0.477748         0.217507   \n3       94.194271     0.571810      0.508089         0.253146   \n4       90.892768     0.567381      0.478923         0.323839   \n..            ...          ...           ...              ...   \n627     93.469083     0.593453      0.523714         0.321761   \n628     92.665032     0.601352      0.521150         0.309096   \n629     93.274918     0.579954      0.514913         0.241137   \n630     87.274997     0.564315      0.490814         0.288426   \n631     90.798947     0.557686      0.482662         0.261403   \n\n     Visitor_3FGARate  Visitor_TmOR%  Visitor_TmDR%  Visitor_BLK%  \\\n0            0.266108      28.615702      77.177177      5.442698   \n1            0.318392      19.164345      77.393453      8.911307   \n2            0.206307      23.866896      76.325088      6.382061   \n3            0.282205      21.128451      76.812500      6.345733   \n4            0.192538      24.899598      76.502732      8.295123   \n..                ...            ...            ...           ...   \n627          0.302852      22.086638      74.622532      9.150613   \n628          0.252419      31.235828      75.572519     10.282776   \n629          0.316263      20.654628      74.140753      9.227723   \n630          0.299755      25.589837      75.406758      7.170966   \n631          0.255802      25.108696      75.139807      9.274194   \n\n     Visitor_TOV%  Visitor_STL%  \n0       12.049168      7.804251  \n1       10.418630      6.645854  \n2       13.575965      7.993861  \n3       13.156047      9.519718  \n4       13.517942      8.438790  \n..            ...           ...  \n627     11.785222      8.670923  \n628     13.567750      7.846969  \n629     13.432928     10.002664  \n630     13.369487      8.775888  \n631     12.258092      6.531878  \n\n[632 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Local_TmOffRtg</th>\n      <th>Local_TmFloor%</th>\n      <th>Local_TmDefRtg</th>\n      <th>Local_Pace</th>\n      <th>Local_TS%</th>\n      <th>Local_eFG%</th>\n      <th>Local_FTARate</th>\n      <th>Local_3FGARate</th>\n      <th>Local_TmOR%</th>\n      <th>Local_TmDR%</th>\n      <th>...</th>\n      <th>Visitor_Pace</th>\n      <th>Visitor_TS%</th>\n      <th>Visitor_eFG%</th>\n      <th>Visitor_FTARate</th>\n      <th>Visitor_3FGARate</th>\n      <th>Visitor_TmOR%</th>\n      <th>Visitor_TmDR%</th>\n      <th>Visitor_BLK%</th>\n      <th>Visitor_TOV%</th>\n      <th>Visitor_STL%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>91.701077</td>\n      <td>0.538690</td>\n      <td>0.477319</td>\n      <td>0.296446</td>\n      <td>0.266108</td>\n      <td>28.615702</td>\n      <td>77.177177</td>\n      <td>5.442698</td>\n      <td>12.049168</td>\n      <td>7.804251</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>8.911307</td>\n      <td>10.418630</td>\n      <td>6.645854</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>91.688075</td>\n      <td>0.535670</td>\n      <td>0.477748</td>\n      <td>0.217507</td>\n      <td>0.206307</td>\n      <td>23.866896</td>\n      <td>76.325088</td>\n      <td>6.382061</td>\n      <td>13.575965</td>\n      <td>7.993861</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>94.194271</td>\n      <td>0.571810</td>\n      <td>0.508089</td>\n      <td>0.253146</td>\n      <td>0.282205</td>\n      <td>21.128451</td>\n      <td>76.812500</td>\n      <td>6.345733</td>\n      <td>13.156047</td>\n      <td>9.519718</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106.326895</td>\n      <td>0.480894</td>\n      <td>100.864813</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>...</td>\n      <td>90.892768</td>\n      <td>0.567381</td>\n      <td>0.478923</td>\n      <td>0.323839</td>\n      <td>0.192538</td>\n      <td>24.899598</td>\n      <td>76.502732</td>\n      <td>8.295123</td>\n      <td>13.517942</td>\n      <td>8.438790</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>93.469083</td>\n      <td>0.593453</td>\n      <td>0.523714</td>\n      <td>0.321761</td>\n      <td>0.302852</td>\n      <td>22.086638</td>\n      <td>74.622532</td>\n      <td>9.150613</td>\n      <td>11.785222</td>\n      <td>8.670923</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>92.665032</td>\n      <td>0.601352</td>\n      <td>0.521150</td>\n      <td>0.309096</td>\n      <td>0.252419</td>\n      <td>31.235828</td>\n      <td>75.572519</td>\n      <td>10.282776</td>\n      <td>13.567750</td>\n      <td>7.846969</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>93.274918</td>\n      <td>0.579954</td>\n      <td>0.514913</td>\n      <td>0.241137</td>\n      <td>0.316263</td>\n      <td>20.654628</td>\n      <td>74.140753</td>\n      <td>9.227723</td>\n      <td>13.432928</td>\n      <td>10.002664</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>87.274997</td>\n      <td>0.564315</td>\n      <td>0.490814</td>\n      <td>0.288426</td>\n      <td>0.299755</td>\n      <td>25.589837</td>\n      <td>75.406758</td>\n      <td>7.170966</td>\n      <td>13.369487</td>\n      <td>8.775888</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>106.494585</td>\n      <td>0.480980</td>\n      <td>119.635230</td>\n      <td>87.074037</td>\n      <td>0.566133</td>\n      <td>0.487970</td>\n      <td>0.290705</td>\n      <td>0.318392</td>\n      <td>19.164345</td>\n      <td>77.393453</td>\n      <td>...</td>\n      <td>90.798947</td>\n      <td>0.557686</td>\n      <td>0.482662</td>\n      <td>0.261403</td>\n      <td>0.255802</td>\n      <td>25.108696</td>\n      <td>75.139807</td>\n      <td>9.274194</td>\n      <td>12.258092</td>\n      <td>6.531878</td>\n    </tr>\n  </tbody>\n</table>\n<p>632 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unscaled = data.iloc[:, :26]\n",
    "X_unscaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0      0\n1      1\n2      1\n3      1\n4      0\n      ..\n627    0\n628    0\n629    1\n630    1\n631    1\nName: Win, Length: 632, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.iloc[:, 26]\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As seen in the input data it is necessary to pre-process the data. Differences in the scales across input variables may\n",
    "increase the difficulty of the problem being modeled. An example of this is that large input values can result in a\n",
    "model that learns large weight values. A model with large weight values is often unstable, meaning that it may suffer\n",
    "from poor performance during learning and sensitivity to input values resulting in higher generalization error."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.02104002, -0.3888855 , -0.81763465, ..., -1.80736562,\n        -0.85192723, -0.33766863],\n       [ 0.02104002, -0.3888855 , -0.81763465, ...,  0.49753131,\n        -2.40555684, -1.34760684],\n       [ 0.02104002, -0.3888855 , -0.81763465, ..., -1.18315728,\n         0.6028549 , -0.17235959],\n       ...,\n       [ 0.06623411, -0.38345585,  2.03779632, ...,  0.70778998,\n         0.46656447,  1.57899721],\n       [ 0.06623411, -0.38345585,  2.03779632, ..., -0.65892841,\n         0.40611638,  0.50944393],\n       [ 0.06623411, -0.38345585,  2.03779632, ...,  0.7386699 ,\n        -0.65285782, -1.44697559]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_unscaled)\n",
    "X = scaler.transform(X_unscaled)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whe we the have data scaled, it is time to divide the original data set into training set and test set. The test set\n",
    "size will be th 20% of the original dataset. Stratifying the data by the results, we manage to maintain the percentages\n",
    "of each class in both resulting sets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Classifier Models\n",
    "We are going to evaluate different models:\n",
    "* Logistic Regression. All different solver will be evaluates (lbfgs, newton-cg, liblinear, sag, saga).\n",
    "* Support Vector Machines. For classification Linear Support Vector Classifier will be used.\n",
    "* Random Forest.\n",
    "* Neuronal Network. For this classification Multi Layer Perceptron Classifier will be evaluated with different solvers\n",
    "(lbfgs, sgd, adam)\n",
    "\n",
    "The models will trained  in loop for 30 times to obtain the mean accuracy, then we will calculate the deviation to\n",
    "display in a plot. In each iteration of the loop the dataset will be splited in training and test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ala_j\\.conda\\envs\\tfg-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\ala_j\\.conda\\envs\\tfg-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\ala_j\\.conda\\envs\\tfg-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\ala_j\\.conda\\envs\\tfg-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\ala_j\\.conda\\envs\\tfg-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression solver=lbfgs -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Logistic Regression solver=newton-cg -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Logistic Regression solver=liblinear -> train scores: [0.699009900990099, 0.700990099009901, 0.6996047430830039, 0.7015810276679841, 0.691699604743083] test scores: [0.6220472440944882, 0.6850393700787402, 0.6349206349206349, 0.7063492063492064, 0.5396825396825397]\n",
      "Logistic Regression solver=sag -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Logistic Regression solver=saga -> train scores: [0.699009900990099, 0.699009900990099, 0.7015810276679841, 0.7015810276679841, 0.6976284584980237] test scores: [0.6220472440944882, 0.6850393700787402, 0.626984126984127, 0.7142857142857143, 0.5396825396825397]\n",
      "Support Vector Machines -> train scores: [0.7029702970297029, 0.7069306930693069, 0.7055335968379447, 0.7134387351778656, 0.7094861660079052] test scores: [0.5905511811023622, 0.6377952755905512, 0.5952380952380952, 0.7063492063492064, 0.5238095238095238]\n",
      "Random Forest -> train scores: [0.9425742574257425, 0.9386138613861386, 0.9407114624505929, 0.9387351778656127, 0.9426877470355731] test scores: [0.6377952755905512, 0.6692913385826772, 0.5238095238095238, 0.6984126984126984, 0.6031746031746031]\n",
      "Neuronal Network solver=lbfgs -> train scores: [0.9425742574257425, 0.9386138613861386, 0.9407114624505929, 0.9387351778656127, 0.9426877470355731] test scores: [0.5826771653543307, 0.6062992125984252, 0.49206349206349204, 0.5952380952380952, 0.49206349206349204]\n",
      "Neuronal Network solver=sgd -> train scores: [0.7663366336633664, 0.7742574257425743, 0.7707509881422925, 0.7628458498023716, 0.7490118577075099] test scores: [0.6062992125984252, 0.6299212598425197, 0.5793650793650794, 0.7222222222222222, 0.6507936507936508]\n",
      "Neuronal Network solver=adam -> train scores: [0.9425742574257425, 0.9386138613861386, 0.9407114624505929, 0.9387351778656127, 0.9426877470355731] test scores: [0.5826771653543307, 0.5984251968503937, 0.5, 0.6904761904761905, 0.5476190476190477]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_LR_lbfgs = []\n",
    "test_accuracy_LR_lbfgs = []\n",
    "train_accuracy_LR_newton_cg = []\n",
    "test_accuracy_LR_newton_cg = []\n",
    "train_accuracy_LR_liblinear = []\n",
    "test_accuracy_LR_liblinear = []\n",
    "train_accuracy_LR_sag = []\n",
    "test_accuracy_LR_sag = []\n",
    "train_accuracy_LR_saga= []\n",
    "test_accuracy_LR_saga= []\n",
    "train_accuracy_SVM = []\n",
    "test_accuracy_SVM = []\n",
    "train_accuracy_RF = []\n",
    "test_accuracy_RF = []\n",
    "train_accuracy_NN_lbfgs = []\n",
    "test_accuracy_NN_lbfgs = []\n",
    "train_accuracy_NN_sgd = []\n",
    "test_accuracy_NN_sgd = []\n",
    "train_accuracy_NN_adam = []\n",
    "test_accuracy_NN_adam = []\n",
    "k_fold = KFold()\n",
    "for k, (train, test) in enumerate(k_fold.split(X, Y)):\n",
    "\n",
    "    LR_lbfgs = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_lbfgs.append(LR_lbfgs.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_lbfgs.append(LR_lbfgs.score(X[test], Y[test]))\n",
    "    LR_newton_cg = LogisticRegression(random_state=0, solver='newton-cg', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_newton_cg.append(LR_newton_cg.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_newton_cg.append(LR_newton_cg.score(X[test], Y[test]))\n",
    "    LR_liblinear = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_liblinear.append(LR_liblinear.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_liblinear.append(LR_liblinear.score(X[test], Y[test]))\n",
    "    LR_sag = LogisticRegression(random_state=0, solver='sag', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_sag.append(LR_sag.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_sag.append(LR_sag.score(X[test], Y[test]))\n",
    "    LR_saga = LogisticRegression(random_state=0, solver='saga', multi_class='ovr').fit(X[train], Y[train])\n",
    "    train_accuracy_LR_saga.append(LR_saga.score(X[train], Y[train]))\n",
    "    test_accuracy_LR_saga.append(LR_saga.score(X[test], Y[test]))\n",
    "\n",
    "    SVM = svm.SVC(kernel='linear', probability=True).fit(X[train], Y[train])\n",
    "    train_accuracy_SVM.append(SVM.score(X[train], Y[train]))\n",
    "    test_accuracy_SVM.append(SVM.score(X[test], Y[test]))\n",
    "\n",
    "    RF = RandomForestClassifier().fit(X[train], Y[train])\n",
    "    train_accuracy_RF.append(RF.score(X[train], Y[train]))\n",
    "    test_accuracy_RF.append(RF.score(X[test], Y[test]))\n",
    "\n",
    "    NN_lbfgs = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1, max_iter=5000).fit(X[train], Y[train])\n",
    "    train_accuracy_NN_lbfgs.append(NN_lbfgs.score(X[train], Y[train]))\n",
    "    test_accuracy_NN_lbfgs.append(NN_lbfgs.score(X[test], Y[test]))\n",
    "    NN_sgd = MLPClassifier(solver='sgd', alpha=1e-5, random_state=1, max_iter=5000).fit(X[train], Y[train])\n",
    "    train_accuracy_NN_sgd.append(NN_sgd.score(X[train], Y[train]))\n",
    "    test_accuracy_NN_sgd.append(NN_sgd.score(X[test], Y[test]))\n",
    "    NN_adam = MLPClassifier(solver='adam', alpha=1e-5, random_state=1, max_iter=5000).fit(X[train], Y[train])\n",
    "    train_accuracy_NN_adam.append(NN_adam.score(X[train], Y[train]))\n",
    "    test_accuracy_NN_adam.append(NN_adam.score(X[test], Y[test]))\n",
    "\n",
    "print(f'Logistic Regression solver=lbfgs -> train scores: {train_accuracy_LR_lbfgs} test scores: {test_accuracy_LR_lbfgs}')\n",
    "print(f'Logistic Regression solver=newton-cg -> train scores: {train_accuracy_LR_newton_cg} '\n",
    "      f'test scores: {test_accuracy_LR_newton_cg}')\n",
    "print(f'Logistic Regression solver=liblinear -> train scores: {train_accuracy_LR_liblinear} '\n",
    "      f'test scores: {test_accuracy_LR_liblinear}')\n",
    "print(f'Logistic Regression solver=sag -> train scores: {train_accuracy_LR_sag} test scores: {test_accuracy_LR_sag}')\n",
    "print(f'Logistic Regression solver=saga -> train scores: {train_accuracy_LR_saga} test scores: {test_accuracy_LR_saga}')\n",
    "print(f'Support Vector Machines -> train scores: {train_accuracy_SVM} test scores: {test_accuracy_SVM}')\n",
    "print(f'Random Forest -> train scores: {train_accuracy_RF} test scores: {test_accuracy_RF}')\n",
    "print(f'Neuronal Network solver=lbfgs -> train scores: {train_accuracy_NN_lbfgs} test scores: {test_accuracy_NN_lbfgs}')\n",
    "print(f'Neuronal Network solver=sgd -> train scores: {train_accuracy_NN_sgd} test scores: {test_accuracy_NN_sgd}')\n",
    "print(f'Neuronal Network solver=adam -> train scores: {train_accuracy_NN_adam} test scores: {test_accuracy_NN_adam}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the data\n",
    "With stored accuracy for training and test set of each model the mean precision and standard deviation are plotted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind: [0 1 2 3 4 5 6 7 8 9] Mean: (10,), sv (10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1120x960 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['LR-lbfgs', 'L-newton-cg', 'LR-liblinear','LR-sag', 'LR-saga', 'SVM', 'RF', 'NN-lbfgs', 'NN-sgd', 'NN-adam']\n",
    "ind = np.arange(10)\n",
    "train_means_list = [sum(train_accuracy_LR_lbfgs)/len(train_accuracy_LR_lbfgs),\n",
    "               sum(train_accuracy_LR_newton_cg)/len(train_accuracy_LR_newton_cg),\n",
    "               sum(train_accuracy_LR_liblinear)/len(train_accuracy_LR_liblinear),\n",
    "               sum(train_accuracy_LR_sag)/len(train_accuracy_LR_sag),\n",
    "               sum(train_accuracy_LR_saga)/len(train_accuracy_LR_saga),\n",
    "               sum(train_accuracy_SVM)/len(train_accuracy_SVM),\n",
    "               sum(train_accuracy_RF)/len(train_accuracy_RF),\n",
    "               sum(train_accuracy_NN_lbfgs)/len(train_accuracy_NN_lbfgs),\n",
    "               sum(train_accuracy_NN_sgd)/len(train_accuracy_NN_sgd),\n",
    "               sum(train_accuracy_NN_adam)/len(train_accuracy_NN_adam)\n",
    "]\n",
    "train_standar_deviation_list = [\n",
    "    statistics.stdev(train_accuracy_LR_lbfgs),\n",
    "    statistics.stdev(train_accuracy_LR_newton_cg),\n",
    "    statistics.stdev(train_accuracy_LR_liblinear),\n",
    "    statistics.stdev(train_accuracy_LR_sag),\n",
    "    statistics.stdev(train_accuracy_LR_saga),\n",
    "    statistics.stdev(train_accuracy_SVM),\n",
    "    statistics.stdev(train_accuracy_RF),\n",
    "    statistics.stdev(train_accuracy_NN_lbfgs),\n",
    "    statistics.stdev(train_accuracy_NN_sgd),\n",
    "    statistics.stdev(train_accuracy_NN_adam),\n",
    "]\n",
    "test_means_list = [sum(test_accuracy_LR_lbfgs)/len(test_accuracy_LR_lbfgs),\n",
    "               sum(test_accuracy_LR_newton_cg)/len(test_accuracy_LR_newton_cg),\n",
    "               sum(test_accuracy_LR_liblinear)/len(test_accuracy_LR_liblinear),\n",
    "               sum(test_accuracy_LR_sag)/len(test_accuracy_LR_sag),\n",
    "               sum(test_accuracy_LR_saga)/len(test_accuracy_LR_saga),\n",
    "               sum(test_accuracy_SVM)/len(test_accuracy_SVM),\n",
    "               sum(test_accuracy_RF)/len(test_accuracy_RF),\n",
    "               sum(test_accuracy_NN_lbfgs)/len(test_accuracy_NN_lbfgs),\n",
    "               sum(test_accuracy_NN_sgd)/len(test_accuracy_NN_sgd),\n",
    "               sum(test_accuracy_NN_adam)/len(test_accuracy_NN_adam)\n",
    "]\n",
    "test_standar_deviation_list = [\n",
    "    statistics.stdev(test_accuracy_LR_lbfgs),\n",
    "    statistics.stdev(test_accuracy_LR_newton_cg),\n",
    "    statistics.stdev(test_accuracy_LR_liblinear),\n",
    "    statistics.stdev(test_accuracy_LR_sag),\n",
    "    statistics.stdev(test_accuracy_LR_saga),\n",
    "    statistics.stdev(test_accuracy_SVM),\n",
    "    statistics.stdev(test_accuracy_RF),\n",
    "    statistics.stdev(test_accuracy_NN_lbfgs),\n",
    "    statistics.stdev(test_accuracy_NN_sgd),\n",
    "    statistics.stdev(test_accuracy_NN_adam),\n",
    "]\n",
    "train_means = np.array(train_means_list)\n",
    "train_standar_deviation = np.array(train_standar_deviation_list)\n",
    "test_means = np.array(test_means_list)\n",
    "test_standar_deviation = np.array(test_standar_deviation_list)\n",
    "print(f'ind: {ind} Mean: {test_means.shape}, sv {test_standar_deviation.shape}')\n",
    "width = 0.35\n",
    "plt.figure(figsize=(14, 12), dpi=80)\n",
    "plt.bar(ind, test_means, width=width, yerr=test_standar_deviation, label='Test Score')\n",
    "plt.bar(ind + width, train_means, width=width,yerr=train_standar_deviation, label='Train Score')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Scores of each model')\n",
    "plt.xticks(ind + width / 2, models)\n",
    "plt.legend()\n",
    "plt.savefig('models-study-figures/models-score.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrices\n",
    "For each model we generate a confusion matrix."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_confusion_matrix(LR_lbfgs, x_test, y_test, display_labels=['Lose', 'Win'], cmap=plt.cm.Blues, normalize=None)\n",
    "\n",
    "plt.title('LR lbfgs solver confusion matrix')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-bfbffe85",
   "language": "python",
   "display_name": "PyCharm (Models Evaluation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}